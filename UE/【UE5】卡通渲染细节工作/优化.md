# 优化

## **12.6.2 资源优化**

### **12.6.2.1 纹理优化**

- **使用压缩格式。**

ASTC由于出色的压缩率，更接近原图的画质，适应更多平台而成为首选的纹理压缩格式。因此，只要可能，尽量使用ASTC。除非部分古老的设备，无法支持ASTC，才考虑使用ETC、PVRTC等纹理压缩格式。详见[12.4.14 Adaptive Scalable Texture Compression](https://www.cnblogs.com/timlly/p/15546797.html#12414-adaptive-scalable-texture-compression)。

- **尽量使用Mipmaps。**

纹理Mipmaps提供提升内存占用来达到降低采样纹理时的数据量，从而降低带宽，提升缓冲命中率，同时还能提升画质效果。鱼和熊掌皆可得，何乐而不为？具体地说表现在以下方面：

1、极大地提高纹理缓存效率来提高图形渲染性能，特别是在强烈缩小的情况下，纹理数据更有可能装在Tile Memory。

2、通过减少不使用mipmapping的纹理采样不足而引起的走样来提高图像质量。

但是，使用Mipmaps会提升33%的内存占用。以下情况需要避免使用：

1、过滤不能被合理地应用，例如对于包含非图像数据的纹理（索引或深度纹理）。

2、永远不会缩小的纹理，比如UI元素，其中texel总是一对一地映射到像素。

- **使用打包的图集。**

打包图集之后，有可能合批渲染或实例化渲染，减少CPU和GPU的带宽。

- **尺寸保持2的N次方。**

尽管目前的图形API都已经支持非2N的次方尺寸（NPOT）的纹理，但有充分的理由建议保持纹理尺寸在2的N次方（POT）：

1、在大多数情况下，POT纹理应该比NPOT纹理更受青睐，因为这为硬件和驱动程序的优化工作提供了最好的机会。（例如纹理压缩、Mimaps生成、缓存行对齐等）

2、2D应用程序应该不会因为使用NPOT纹理而出现性能损失（除非可能在上传时）。2D应用程序可以是浏览器或其他呈现UI元素的应用程序，其中NPOT纹理以一对一的texel到pixel映射显示。

3、保证长和宽都是32像素倍数的纹理，以便纹理上传可以让硬件优化。

- **最小化纹理尺寸。**
- **最小化纹理位深。**
- **最小化纹理组件数量。**
- **利用纹理通道打包多张贴图。**例如将材质的粗糙度、高光度、金属度、AO等贴图打包到同一张纹理的RGBA通道上。

### **12.6.2.2 顶点优化**

- **使用分离位置的交错的顶点布局。**原因详见[12.4.11 Index-Driven Vertex Shading](https://www.cnblogs.com/timlly/p/15546797.html#12411-index-driven-vertex-shading)。
- **使用合适的顶点和索引存储格式。**降低数据精度可以降低内存、带宽，提高计算单元运算量。目前主流移动端GPU支持的顶点格式有：

```undefined
GL_BYTE
GL_UNSIGNED_BYTE
GL_SHORT
GL_UNSIGNED_SHORT
GL_FIXED
GL_FLOAT
GL_HALF_FLOAT
GL_INT_2_10_10_10_REV
GL_UNSIGNED_INT_2_10_10_10_REV
```

- **考虑几何物体实例化**。现代移动端GPU普遍支持实例化渲染，通过提交少量的几何数据可以绘制多次，来降低带宽。每个实例允许拥有自己的数据，如颜色、变换矩阵、光照等。常用于树、草、建筑物、群兵等物体。
- **图元类型使用三角形。**现代GPU设计便是处理三角形，如果是四边形之类的很可能会降低效率。
- **减少索引数组大小。**如使用条带（strip）格式代替简单列表格式，使用原始的有效索引代替退化三角形。
- **对于转换后缓存（ post-transform cache），局部地优化索引。**
- **避免使用低空间一致性的索引缓冲区。**会降低缓存命中率。
- **使用实例属性来解决任何统一的缓冲区大小限制。** 例如，16KB的统一缓冲区。
- **每个实例使用2的N次方个顶点。**
- **优先使用gl_InstanceID到统一缓冲区或着色器存储缓冲区的索引查找，而不是逐实例属性数据。**

### **12.6.2.3 网格优化**

- **使用LOD。**

使用网格的LOD可以提升渲染性能和降低带宽。相反，不使用LOD，会造成性能瓶颈。

![img](https://img2020.cnblogs.com/blog/1617944/202111/1617944-20211118220127622-1613380270.png)

*同个网格不同LOD的线框模式。*

以下是浪费计算和内存资源的例子:

1、使用大量多边形的对象不会覆盖屏幕上的一个小区域，比如一个遥远的背景对象。

2、使用多边形的细节，将永远不会看到由于相机的角度或裁剪（如物体在视野锥之外）。

3、为对象使用大量的图元。实际上可以用更少的图元来绘制，还能保证视觉效果不损失。

- **简化模型，合并顶点。**通过合并相邻很近的顶点，可以有效减少网格顶点数量，利用网格简化技术，可以生成良好的LOD数据。
- **离线合并靠在一起的小网格。**如沙石、植被等。
- **单个网格的顶点数不能超过65k。**主要是移动端的顶点索引精度是16位，最大值是65535。
- **删除看不见的图元。**例如箱子内部的三角形。
- **使用简单的几何物体，配合法线贴图、凹凸贴图增加细节。**
- **避免小面积的三角形。**

Quad的绘制机制，会导致小面积的三角形极大提升OverDraw。在PowerVR硬件上，对于覆盖低于32个像素的三角形，会影响光栅化的效率，导致性能瓶颈。

提交许多小三角形可能会导致硬件在顶点阶段花费大量时间处理它们，此阶段主要影响因素是三角形的数量而不是大小。尤其会导致平铺加速器( tile accelerator，TA)固定功能硬件的瓶颈。数量众多的小三角形将导致对位于系统内存中的参数缓冲区（parameter buffer）的访问次数增加，增加内存带宽占用。

- **保证网格内每个图元至少能创建10~20个像素。**
- **使用几乎等边的三角形。**可以使面积与边长的比例最大化，减少生成的片元Quad的数量。
- **避免细长的三角形。**

和小三角形类似，细长三角形（下图红色所示）也会产生更多无效的像素，占用更高的GPU资源，提高Overdraw。

![img](https://img2020.cnblogs.com/blog/1617944/202111/1617944-20211118220139737-1926599539.png)

- **避免使用扇形或类似的几何布局。**三角形扇形的中心点具有较高的三角形密度，以致每个三角形具有非常低的像素覆盖率。可以考虑Tile轴对齐的切割，但会引入更多三角形。（下图）

![img](https://img2020.cnblogs.com/blog/1617944/202111/1617944-20211118220203561-621550234.png)

*扇形（图左）进行Tile轴对齐的切割后产生的三角形数量（图右）。*

## **12.6.3 Shader优化**

### **12.6.3.1 语句优化**

- **使用适当的数据类型。**

在代码中使用最合适的数据类型可以使编译器和驱动程序优化代码，包括shader指令的配对。使用vec4数据类型而不是float可能会阻止编译器执行优化。

```glsl
int4 ResultOfA(int4 a) 
{
    return a + 1; // int4和int相加, 只需要1条指令.
}

int4 ResultOfA(int4 a) 
{
    return a + 1.0; // int4和float相加, 需要3条指令: int4 -> float4 -> 相加 -> int4
}
```

- **减少类型转换。**

```glsl
uniform sampler2D ColorTexture;
in vec2 TexC;
vec3 light(in vec3 amb, in vec3 diff)
{
    // 纹理采样返回vec4, 会隐性转换成vec3, 多出1条指令.
    vec3 Color = texture(ColorTexture, TexC); 
    Color *= diff + amb;
    return Color;
}

// 以下代码中, 输入参数/临时变量/返回值都是vec4, 没有隐性类型转换, 比上面代码少1条指令.
uniform sampler2D ColorTexture;
in vec2 TexC;
vec4 light(in vec4 amb, in vec4 diff)
{
    vec4 Color = texture(Color, TexC);
    Color *= diff + amb;
    return Color;
}
```

- **打包标量常数。**

将标量常数填充到由四个通道组成的向量中，大大提高了硬件获取效率。在GPU骨骼动画系统中，可增加蒙皮的骨骼数量。

```glsl
float scale, bias;  // 两个float值.
vec4 a = Pos * scale + bias; // 需要两条指令.

vec2 scaleNbias; // 将两个float值打包成一个vec2
vec4 a = Pos * scaleNbias.x + scaleNbias.y; // 一条指令(mad)完成.
```

- **使用标量操作。**

要小心标量操作向量化，因为相同的向量化输出需要更多的时间周期。例如：

```glsl
highp vec4 v1, v2;
highp float x, y;

// Bad!!
v2 = (v1 * x) * y; // vector*scalar接着vector*scalar总共8个标量muladd.
// Good!!
v2 = v1 * (x * y); // scalar*scalar接着vector*scalar总共5个标量muladd.
```

### **12.6.3.2 状态优化**

- **尽量使用const。**

如果正确使用，const关键字可以提供显著的性能提升。例如，在main()块之外声明一个const数组的着色器比没有的性能要好得多。

另一个例子是使用const值引用数组成员。如果值是const，GPU可以提前知道数字不会改变，并且数据可以在运行着色器之前被预读取，从而降低Stall。

- **保持着色器指令数量合理**。

过长的着色器通常比较低效，比如需要在一个着色器中包含相对于纹理获取数量的许多指令槽，可以考虑将算法分成几个部分。

由算法的一部分生成的值可以存储到纹理中，然后通过采样纹理来获取。然而，这种方法在内存带宽方面代价昂贵。以下情形也会降低纹理采样效率：

1、使用三线性、各向异性过滤、宽纹理格式、3D和立方体贴图纹理、纹理投影；

2、使用不同Lod梯度的纹理查找；

3、跨像素Quad的梯度计算。

- **最小化shader指令数。**

现代shader编译器通常会执行特定的指令优化，但它不是自动有效的。很多时候需要人工介入，分析着色器，尽可能减少指令，即使是节省一条指令也值得。

- **避免使用全能着色器（uber-shader）。**

uber-shader使用静态分支组合多个着色器到一个单一的着色器。如果试图减少状态更改和批处理绘制调用，那么是有意义的。然而，通常会增加GPR数量，从而影响性能。

- **高效地采样纹理。**

纹理采样（过滤）的方式很多，性能和效果通常成反比：

![img](https://img2020.cnblogs.com/blog/1617944/202111/1617944-20211118220215565-1340536685.png)

*纹理的部分过滤类型及对应效果图。*

要做到高效地采样纹理，必须遵循以下规则：

1、避免随机访问，保持采样在同一个2x2像素Quad内，命中率高，着色器更有效率。

2、避免使用3D纹理。由于需要执行复杂的过滤来计算结果值，从体积纹理中获取数据通常比较昂贵。

3、限制Shader纹理采样数量。在一个着色器中使用四个采样器是可以接受的，但采样更多的纹理可能会导致性能瓶颈。

4、压缩所有纹理。这允许更好的内存使用，转化为渲染管道中更少的纹理停顿。

5、考虑开启Mipmaps。Mipmaps有助于合并纹理获取，并有助于以增加内存占用为代价的提高性能。同时还能降低带宽，提升缓存命中率。

6、尽量使用简单的纹理过滤。性能从高到低（效果从低到高）的采样方式：最近点（nearest）、双线性（bilinear）、立方（cubic）、三线性（tri-linear）、各向异性（anisotropic）。越复杂的采样方式，会读取越多的数据，从而提升内存访问带宽，降低缓存命中率，造成更大的延迟。需要格外注意这一点。

7、优先使用texelFetch / texture()，通常会比纹理采样效率更高（但需要工具分析验证）。

8、谨慎对待预计算纹理LUT。实时渲染中，很常将复杂计算的结果编码到纹理中，并将其用作查找表（如IBL的辐照度图，皮肤次表面散射预积分图）。这种方式只会在着色器是瓶颈时提升性能。如果函数参数和查找表中的纹理坐标在相邻片元之间相差很大，那么缓存效率就会受到影响。应该执行性能概要分析，以确定此法是否有实际上的提升。

9、使用mediump sampler代替highp sampler，后者的速度是前者的一半。

10、各向异性过滤（Anisotropic Filtering，AF）优化建议：

（1）先使用2x各向异性，评估它是否满足质量要求。较高的样本数量可以提高质量，但也会带来效益递减，并且往往与性能成本不相称。

（2）考虑使用2x双线性各向异性，而非三线性各向同性。在各向异性高的区域，2x双线性算法速度更快，图像质量更好。注意，通过切换到双线性过滤，可以在mipmap级别之间的过度点上看到接缝。

（3）只对受益最大的对象使用各向异性和三线性滤波。注意，8x三线性各向异性的消耗是简单双线性过滤的16倍！

- **尽量避免依赖纹理读取（Dependent texture read）。**

依赖纹理读取是一种特殊的纹理读取，其中纹理坐标依赖于着色器中的一些计算（而不是某种规律变化）。由于这个计算的值不能提前知道，它不可能预取纹理数据，因此在着色器处理降低缓存命中率，引发卡顿。

顶点着色纹理查找总是被视作依赖纹理读取，就像片元着色中基于`zw`通道变化的纹理读取。在一些驱动程序和平台版本中，如果给定带有无效`w`的Vec3或Vec4，则Texture2DProj()也可以作为依赖纹理读取。

与依赖纹理读取相关的成本在某种程度上可以通过硬件线程调度来抵消，特别是着色器涉及大量的数学计算。这个过程涉及到线程调度程序暂停当前线程并在另一个线程中交换到USC上的处理。这个交换的线程将尽可能多地处理，一旦纹理获取完成，原始线程将被交换回（下图）。

![img](https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001800006-1870518462.png)

*GPU的Context需要访问缓存或内存，会导致若干个时钟周期的延迟，此时调度器会激活第二组Context以利用ALU。*

![img](https://img2018.cnblogs.com/blog/1617944/201909/1617944-20190906001809771-488438022.png)

*GPU越多Context可用就越可以提升运算单元的吞吐量，上图的18组Context的架构可以最大化地提升吞吐量。*

虽然硬件会尽力隐藏内存延迟，但为了获得良好的性能，应该尽可能避免依赖纹理读取。应用程序尽量在片元着色器执行之前就计算出纹理坐标。

- **避免使用动态分支**。

动态分支会延迟shader指令时间，但如果分支的条件是常量，则编译器就会在编译器进行优化。否则如果条件语句和uniform、可变变量相关，则无法优化。其它建议：

1、最小化空间相邻着色线程中的动态分支。

2、使用min(), max(), clamp(), mix(), saturate()等内置函数避免分支语句。

3、检查分支相对于计算的好处。例如，跳过距离相机阈值以上的像素进行光照计算，通常比直接进行计算会更快。

- **打包shader插值数据。**

着色器插值需要**GPR(General Purpose Register，通用寄存器)**传递数据到像素着色器。GPR的数量有限，若占满，会导致Stall，所以尽量减少它们的使用。

能使用uniform的就不用varying。将值打包在一起，因为所有varying都有四个组件，不管它们是否被使用，比如将两个vec2纹理坐标放入一个vec4。也存在其它更有创意的打包和实时数据压缩。

- **减少着色器GRP的占用。**

占用越多的**GPR(General Purpose Register，通用寄存器)**意味着计算量大，如果没有足够的可用寄存器时，可能会导致寄存器溢出，从而导致性能欠佳。以下一些措施可以减少GRP的占用：

1、使用更简单的着色器。

2、修改GLSL以减少哪怕是一条指令，有时也能减少一个GPR的占用。

3、不展开循环（unrolling loop）也可以节省GPRs，但取决于着色器编译器。

4、根据目标平台配置着色器，确保最终选择的解决方案是最高效的。

5、展开循环倾向于将纹理获取放到着色器顶部，导致需要更多的GPR来保存多个纹理坐标并同时获取结果。

6、最小化全局变量和局部变量的数量。减少局部变量的作用域。

7、最小化数据维度。比如能用2维的就不要用3维。

8、使用精度更小的数据类型。如FP16代替FP32。

- **在着色器上避免常量的数学运算**。

自从着色器出现以来，几乎每一款发行的游戏都在着色器常量上花费了不必要的数学运算指令。需要在着色器中识别这些指令，将这些计算移到CPU上。在编译后的代码中识别着色器常量的数学运算可能更容易。

- **避免在像素着色器中使用discard等语句。**

一些开发者认为，在像素着色器中手动丢弃(也称为杀死)像素可以提高性能。实际上没有那么简单，有以下原因:

1、如果线程中的一些像素被杀死，而同Quad的其他像素没有，着色器仍然执行。

2、依赖于编译器如何生成微代码(Microcode)。

3、某些硬件架构（如PowerVR）会禁用TBDR的优化，造成渲染管线的Stall和数据回写。

- **避免在像素着色器中修改深度**。

理由类同上一条。

- **避免在VS里采样纹理。**

虽然目前主流的GPU已经使用了统一着色器架构，VS和PS的执行性能相似。但是，还是得确保在VS对纹理操作是局部的，并且纹理使用压缩格式。

- **拆分特殊的绘制调用**。

如果一个着色器瓶颈在于GPR和/或纹理缓存，拆分Draw Call到多个Pass反而可以增加性能。但结果难以预测，应以实际性能测试为准。

- **尽量使用低精度浮点数**。

FP16的运算性能通常是FP32的两倍，所以shader中尽可能使用低精度浮点数。

```glsl
precision mediump float;

#ifdef GL_FRAGMENT_PRECISION_HIGH
    #define NEED_HIGHP highp
#else
    #define NEED_HIGHP mediump
#endif
        
varying vec2 vSmallTexCoord;
varying NEED_HIGHP vec2 vLargeTexCoord;
```

UE也对浮点数做了封装，以便在不同平台和画质下自如低切换浮点数的精度。

- **尽量将PS运算迁移到VS。**

通常情况下，顶点数量明显小于像素数量。通过将计算从像素着色器迁移到顶点着色器，可以减少GPU工作负载，有助于消除冗余计算。

例如，拆分光照计算的漫反射和高光反射，将漫反射迁移到VS，而高光反射保留在PS中，这样能获得效果和效率良好平衡的光照结果。

- **优化Uniform / Uniform Buffer。**

1、保持Uniform数据尽可能地小。不超过128字节，以便在多数GPU良好地运行任意给定的着色器。

2、将Uniform改成OpenGL ES的带有#define的编译时常量，Vulkan的专用常量，或者着色源中的静态语法。

3、避免Uniform的向量或矩阵中存在常量，例如总是0或1的元素。

4、优先使用glUniform()设置uniform，而不是从buffer中加载。

5、不要动态地索引uniform数组。

6、不要过度使用实例化。使用gl_InstanceID访问Instanced uniform就是动态索引，无法使用寄存器映射的Uniform。

7、将Uniform的相关计算尽可能地移到CPU的应用层。

8、尽量使用uniform buffer代替着色器存储缓冲区（shader storage buffer）。只要uniform buffer空间充足，就尽量使用之。如果uniform buffer对象在GLSL中静态索引，并且足够小，驱动程序或编译器可以将它们映射到用于默认统一块全局变量的相同硬件常量RAM中。

- **保持UBO占用尽可能地小。**

如果UBO小于8k，则可以放进常量存储器，将获得更高的性能。否则，会存储在全局内存，存取时间周期显著增加。

- **选择更优的着色算法。**

选择更优的有效的算法比低级别（指令级）的优化更重要。因为前者更能显著地提升性能。

- **选择合适的坐标空间。**

顶点着色器的一个常见错误是在模型空间、世界空间、视图空间和剪辑空间之间执行不必要的转换。如果模型世界转换是刚体转换(只包含旋转、平移、镜像、光照或类似)，那么可以直接在模型空间中进行计算。

避免将每个顶点的位置转换为世界或视图空间，更好的做法是将uniforms(如光的位置和方向)转换到模型空间，因为它是一个逐网格的操作，计算量更少。在必须使用特定空间的情况下（例如立方体映射反射），最好整个Shader都使用这个空间，避免在同一个shader中使用多个坐标空间。

- **优化插值（Varying）变量。**

减少插值变量数量，减少插值变量的维度，删除无用（片元着色器未使用）的插值变量，紧凑地打包它们，尽可能使用中低精度数据类型。

- **优化原子（Atomic）。**

原子操作在许多计算算法和一些片元算法中比较常见。通过一些微小的修改，原子操作允许许多算法在高度并行的GPU上实现，否则将是串行的。

原子的关键性能问题是争用（contention）。原子操作来自不同的着色器核心。要达到相同的高速缓存行（cache line），需要数据一致性访问L2高速缓存。

通过将原子操作保持在单个着色器核心来避免争用，当着色器核心在L1中控制必要的缓存行时，原子是最高效的。以下是具体的优化建议：

1、考虑在算法设计中使用原子时如何避免争用。

2、考虑将原子间距设置为64个字节，以避免多个原子在同一高速缓存行上竞争。

3、考虑是否可以通过累积到共享内存原子中来分摊争用。然后，让其中的一个线程在工作组的末尾推送全局原子操作。

- **充分利用指令缓存（Instruction cache）。**

着色器核心指令缓存是一个经常被忽略的影响性能的因素。由于并发运行的线程数量众多，因此足够重视指令缓存对性能的重要性。优化建议如下：

1、使用较短的着色器与更多的线程，而不是更长的色器与少量的线程。较短的着色器指令在缓存中更有可能被命中。

2、使用没有动态分支的着色器。动态分支会减少时间局部性，增加缓存压力。

3、不要过于激进地展开循环（unroll loop），尽管一些展开可能有所帮助。

4、不要从相同的源代码生成重复的着色程序或二进制文件。

5、小心同个tile内存在多个可见的片元着色（即Overdraw）。所有未被Early-ZS或FPK/HSR剔除的片元着色器，必须加载和执行，增加缓存压力。

### **12.6.3.3 汇编级优化**

建议Shader低级别优化只在性能异常敏感的地方或者优化后期才关注和执行，否则可能事倍功半。

对于GPU指令集，很多指令可以在1个时钟周期完成，但有些指令则需要多个周期。下图是PowerVR的部分可以在1个时钟周期完成的指令：

![img](https://img2020.cnblogs.com/blog/1617944/202111/1617944-20211118220232742-1519294238.png)

对于峰值性能的测量，若以PowerVR 500MHz G6400为例，则常见指令的峰值性能数据如下：

| 数据类型     | 操作                 | 单指令操作数 | 单指令时钟 | 理论吞吐量                                |
| ------------ | -------------------- | ------------ | ---------- | ----------------------------------------- |
| 16-bit float | **Sum-Of-Products**  | 6            | 1          | (0.5 × 4 × 16 × 6) ÷ 1 = **192 GFLOPS**   |
| float        | **Multiply-and-Add** | 4            | 1          | (0.5 × 4 × 16 × 4) ÷ 1 = **128 GFLOPS**   |
| float        | **Multiply**         | 2            | 1          | (0.5 × 4 × 16 × 2) ÷ 1 = **64 GFLOPS**    |
| float        | **Add**              | 2            | 1          | (0.5 × 4 × 16 × 2) ÷ 1 = **64 GFLOPS**    |
| float        | **DivideA**          | 1            | 4          | (0.5 × 4 × 16 × 1) ÷ 4 = **8 GFLOPS**     |
| float        | **DivideB**          | 1            | 2          | (0.5 × 4 × 16 × 1) ÷ 2 = **16 GFLOPS**    |
| int          | **Multiply-and-Add** | 2            | 1          | (0.5 × 4 × 16 × 2) ÷ 1 = **64 GILOPS**    |
| int          | **Multiply**         | 1            | 1          | (0.5 × 4 × 16 × 1) ÷ 1 = **32 GILOPS**    |
| int          | **Add**              | 1            | 1          | (0.5 × 4 × 16 × 1) ÷ 1 = **32 GILOPS**    |
| int          | **Divide**           | 1            | 30         | (0.5 × 4 × 16 × 1) ÷ 30 = **1.07 GILOPS** |

性能估计以理论上的峰值来计算，实际上由于各种依赖、降频、上下文切换等原因，可能实际峰值达不到。

默认情况下，编译器将浮点除法实现为两个范围缩减，然后是倒数和乘法指令，需要4个循环。

另外，重点提一下整数除法，效率极低，应该避免，可以先转成float再除。

更多指令的消耗情况可参见[Complex Operations](https://docs.imgtec.com/Profiling_and_Optimisations/ComputeDevelopmentRecommendations/dita/topics/complexoperations.html)。

下面是常见的低级别优化措施（以PowerVR为例，其它GPU类似但不完全相同，应以实测为准）。

1、为了充分利用USC核心，必须始终以乘-加(MAD)形式编写数学表达式。例如，更改以下表达式以使用MAD表单可以减少50%的周期成本:

```glsl
fragColor.x = (t.x + t.y) * (t.x - t.y); // 2 cycles
{sop, sop, sopmov}
{sop, sop}
-->
fragColor.x = t.x * t.x + (-t.y * t.y); // 1 cycle
{sop, sop}
```

2、通常最好以倒数形式写除法，因为倒数形式直接由指令`RCP`支持。完成数学表达式的简化可以进一步提高性能。

```glsl
fragColor.x = (t.x * t.y + t.z) / t.x; // 3 cycles
{sop, sop, sopmov}
{frcp}
{sop, sop}
-->
fragColor.x = t.y + t.z * (1.0 / t.x); // 2 cycles
{frcp}
{sop, sop}
```

3、`sign(x)`的结果可能是以下几种：

```glsl
if (x > 0)
{
    return 1;
}
else if(x < 0)
{
    return -1;
}
else
{
    return 0;
}
```

但利用`sign`来获取符号并非最优选择：

```glsl
fragColor.x = sign(t.x) * t.y; // 3 cycles
{mov, pck, tstgez, mov}
{mov, pck, tstgez, mov}
{sop, sop}
-->
fragColor.x = (t.x >= 0.0 ? 1.0 : -1.0) * t.y; // 2 cycles
{mov, pck, tstgez, mov}
{sop, sop}
```

4、使用`inversesqrt`代替`sqrt`：

```glsl
fragColor.x = sqrt(t.x) > 0.5 ? 0.5 : 1.0; // 3 cycles
{frsq}
{frcp}
{mov, mov, pck, tstg, mov}
-->
fragColor.x = (t.x * inversesqrt(t.x)) > 0.5 ? 0.5 : 1.0; // 2 cycles
{frsq}
{fmul, pck, tstg, mov}
```

5、normalize的取反优化：

```glsl
fragColor.xyz = normalize(-t.xyz); // 7 cycles
{mov, mov, mov}
{fmul, mov}
{fmad, mov}
{fmad, mov}
{frsq}
{fmul, fmul, mov, mov}
{fmul, mov}
-->
fragColor.xyz = -normalize(t.xyz); // 6 cycles
{fmul, mov}
{fmad, mov}
{fmad, mov}
{frsq}
{fmul, fmul, mov, mov}
{fmul, mov}
```

6、abs、dot、neg、clamp、saturate等优化：

```glsl
// abs
fragColor.x = abs(t.x * t.y); // 2 cycles
{sop, sop}
{mov, mov, mov}
-->
fragColor.x = abs(t.x) * abs(t.y); // 1 cycle
{sop, sop}

// dot
fragColor.x = -dot(t.xyz, t.yzx); // 3 cycles
{sop, sop, sopmov}
{sop, sop}
{mov, mov, mov}
-->
fragColor.x = dot(-t.xyz, t.yzx); // 2 cycles
{sop, sop, sopmov}
{sop, sop}

// clamp
fragColor.x = 1.0 - clamp(t.x, 0.0, 1.0); // 2 cycles
{sop, sop, sopmov}
{sop, sop}
-->
fragColor.x = clamp(1.0 - t.x, 0.0, 1.0); // 1 cycle
{sop, sop}

// min / clamp
fragColor.x = min(dot(t, t), 1.0) > 0.5 ? t.x : t.y; // 5 cycles
{sop, sop, sopmov}
{sop, sop}
{mov, fmad, tstg, mov}
{mov, mov, pck, tstg, mov}
{mov, mov, tstz, mov}
-->
fragColor.x = clamp(dot(t, t), 0.0, 1.0) > 0.5 ? t.x : t.y; // 4 cycles
{sop, sop, sopmov}
{sop, sop}
{fmad, mov, pck, tstg, mov}
{mov, mov, tstz, mov}
```

7、Exp、Log、Pow：

```glsl
// exp2
fragColor.x = exp2(t.x); // one cycle
{fexp}

// exp
float exp( float x )
{
    return exp2(x * 1.442695); // 2 cycles
    {sop, sop}
    {fexp}
}

// log2
fragColor.x = log2(t.x); // 1 cycle
{flog}

// log
float log( float x )
{
    return log2(x * 0.693147); // 2 cycles
    {sop, sop}
    {flog}
}

// pow
float pow( float x, float y )
{
    return exp2(log2(x) * y); // 3 cycles
    {flog}
    {sop, sop}
    {fexp}
}
```

执行效率从高到低：exp2 = log2 > exp = log > pow。

8、Sin、Cos、Sinh、Cosh：

```glsl
// sin
fragColor.x = sin(t.x); // 4 cycles
{fred}
{fred}
{fsinc}
{fmul, mov} // plus conditional

// cos
fragColor.x = cos(t.x); // 4 cycles
{fred}
{fred}
{fsinc}
{fmul, mov} // plus conditional

// cosh
fragColor.x = cosh(t.x); // 3 cycles
{fmul, fmul, mov, mov}
{fexp}
{sop, sop}

// sinh
fragColor.x = sinh(t.x); // 3 cycles
{fmul, fmul, mov, mov}
{fexp}
{sop, sop}
```

执行效率从高到低：sinh = cosh > sin = cos。

9、Asin, Acos, Atan, Degrees, and Radians：

```glsl
fragColor.x = asin(t.x); // 67 cycles
fragColor.x = acos(t.x); // 79 cycles
fragColor.x = atan(t.x); // 12 cycles (许多判断条件)

fragColor.x = degrees(t.x); // 1 cycle
{sop, sop}

fragColor.x = radians(t.x); // 1 cycle
{sop, sop}
```

从上可知，acos和asin效率极其低，高达79个时钟周期；其次是atan，12个时间周期；最快的是degrees和radians，1个时钟周期。

10、向量和矩阵：

```glsl
fragColor = t * m1; // 4x4 matrix, 8 cycles
{mov}
{wdf}
{sop, sop, sopmov}
{sop, sop, sopmov}
{sop, sop}
{sop, sop, sopmov}
{sop, sop, sopmov}
{sop, sop}

fragColor.xyz = t.xyz * m2; // 3x3 matrix, 4 cycles
{sop, sop, sopmov}
{sop, sop}
{sop, sop, sopmov}
{sop, sop}
```

向量和矩阵的维度的数量越少效率越高，所以尽量缩减它们的维度。

11、标量、向量运算：

```glsl
fragColor.x = length(t-v); // 7 cycles
fragColor.y = distance(v, t);
{sopmad, sopmad, sopmad, sopmad}
{sop, sop, sopmov}
{sopmad, sopmad, sopmad, sopmad}
{sop, sop, sopmov}
{sop, sop}
{frsq}
{frcp}
-->
fragColor.x = length(t-v); // 9 cycles
fragColor.y = distance(t, v);
{mov}
{wdf}
{sopmad, sopmad, sopmad, sopmad}
{sop, sop, sopmov}
{sop, sop, sopmov}
{sop, sop}
{frsq}
{frcp}
{mov}

fragColor.xyz = normalize(t.xyz); // 6 cycles
{fmul, mov}
{fmad, mov}
{fmad, mov}
{frsq}
{fmul, fmul, mov, mov}
{fmul, mov}
-->
fragColor.xyz = inversesqrt( dot(t.xyz, t.xyz) ) * t.xyz; // 5 cycles
{sop, sop, sopmov}
{sop, sop}
{frsq}
{sop, sop}
{sop, sop}

fragColor.xyz = 50.0 * normalize(t.xyz); // 7 cycles
{fmul, mov}
{fmad, mov}
{fmad, mov}
{frsq}
{fmul, fmul, mov, mov}
{fmul, fmul, mov, mov}
{sop, sop}
-->
fragColor.xyz = (50.0 * inversesqrt( dot(t.xyz, t.xyz) )) * t.xyz; // 6 cycles
{sop, sop, sopmov}
{sop, sop}
{frsq}
{sop, sop, sopmov}
{sop, sop}
{sop, sop}
```

以下是GLSL部分内置函数的展开形式：

```glsl
vec3 cross( vec3 a, vec3 b )
{
    return vec3( a.y * b.z - b.y * a.z,
                 a.z * b.x - b.z * a.x,
                 a.x * b.y - b.y * a.y );
}

float distance( vec3 a, vec3 b )
{
    vec3 tmp = a – b;
    return sqrt( dot(tmp, tmp) );
}

float dot( vec3 a, vec3 b )
{
    return a.x * b.x + a.y * b.y + a.z * b.z;
}

vec3 faceforward( vec3 n, vec3 I, vec3 Nref )
{
    if( dot( Nref, I ) < 0 ) 
    { 
      return n;
    }
    else
    {
      return –n:
    }
}

float length( vec3 v )
{
    return sqrt( dot(v, v) );
}

vec3 normalize( vec3 v )
{
    return v / sqrt( dot(v, v) );
}

vec3 reflect( vec3 N, vec3 I )
{
    return I - 2.0 * dot(N, I) * N;
}

vec3 refract( vec3 n, vec3 I, float eta )
{
    float k = 1.0 - eta * eta * (1.0 - dot(N, I) * dot(N, I));
    if (k < 0.0)
        return 0.0; 
    else
        return eta * I - (eta * dot(N, I) + sqrt(k)) * N;
}
```

12、分组运算。

将标量和向量一次分组，可以提升效率：

```glsl
fragColor.xyz = t.xyz * t.x * t.y * t.wzx * t.z * t.w; // 7 cycles
{sop, sop, sopmov}
{sop, sop, sopmov}
{sop, sop}
{sop, sop, sopmov}
{sop, sop}
{sop, sop, sopmov}
{sop, sop}
-->
fragColor.xyz = (t.x * t.y * t.z * t.w) * (t.xyz * t.wzx); // 4 cycles
{sop, sop, sopmov}
{sop, sop, sopmov}
{sop, sop}
{sop, sop}
```

### **12.6.1.3 带宽优化**

- **注意数据的存放位置。**如：RAM、VRAM、Tile Buffer、GPU Cache，减少不必要的数据传输。

- **关注数据的访问类型。**如：是只读还是只写操作，是否需要原子操作，是否需要缓存一致性。

- 关注缓存数据的可行性，硬件可以缓存数据以供GPU后续操作快速访问。

  可以通过以下几点提升缓存命中率：

  - 提高传输速度，确保客户端顶点数据缓冲区被用于尽可能少的绘制调用。理想情况下，应用程序永远不应该使用它们。
  - 减少GPU在执行调度或绘制调用时需要访问的数据量。这样可以让尽量多的数据放到缓存行，提升命中率。

- **使用纹理压缩格式。**优先ASTC，其次是ETC、PVRTC、BC等压缩格式。GPU的硬件通常都支持这类压缩格式，可以快速地编解码它们，并且可以一次性读取更多的纹素内容到GPU的缓存行，提升缓存命中率。

- **使用位数更少的像素格式。**如RGB565比RGB888少8位，ASTC_6X6代替ASTC_4x4等。Adreno支持的像素格式参见[Spec Sheets](https://developer.qualcomm.com/sites/default/files/docs/adreno-gpu/developer-guide/gpu/spec_sheets.html)。

- **使用半精度（如FP16）取代高精度（FP32）数据。**如模型顶点和索引数据，并且可以使用SOA（Structure of Array）数据布局，而不用AOS。

- **降分辨率渲染，后期再放大。**可以减少带宽、计算量，减少设备热发热量。

- **尽量减少绘制次数。**绘制数量的减少可以减少CPU和GPU之间、GPU内部的带宽和消耗。

- **确保数据存储在On-Chip内。**

利用PLS、Subpass的特性，可以实现移动端的延迟渲染、粒子软混合等。下表是PowerVR GX6250在实现延迟渲染时，使用不同的位数和性能的关系：

| 配置         | 时间/帧（ms） |
| ------------ | ------------- |
| 96bit + D32  | 20            |
| 128bit + D32 | 21            |
| 160bit + D32 | 23            |
| 192bit + D32 | 24            |
| 224bit + D32 | 28            |
| 256bit + D32 | 29            |
| 288bit + D32 | 39            |

以上可知，当位数大于256，超过GX6250的最大位数，数据无法完全存储在On-Chip内，会外溢到全局内存，导致每帧时间暴增10ms，增幅为34.5%。

因此，对每像素的数据进行精心的组装、优化和压缩，保持数据能够完全容纳于On-Chip内，可有效提升性能，节省带宽。

- **避免多余的副本。**

确保使用相同内存的硬件组件（CPU、图形核心、摄像机接口和视频解码器等）都访问相同的数据，而不需要进行任何中间复制。

- **使用正确的标记创建Buffer、纹理等内存。**部分Mali GPU（如Bifrost）执行以下几个标记组合：

1、DEVICE_LOCAL_BIT | HOST_VISIBLE_BIT | HOST_COHERENT_BIT

2、DEVICE_LOCAL_BIT | HOST_VISIBLE_BIT | HOST_CACHED_BIT

3、DEVICE_LOCAL_BIT | HOST_VISIBLE_BIT | HOST_COHERENT_BIT | HOST_CACHED_BIT

4、DEVICE_LOCAL_BIT | LAZILY_ALLOCATED_BIT

其中HOST_VISIBLE_BIT | HOST_COHERENT_BIT | HOST_CACHED_BIT的内存类型说明如下：

1、提供CPU上的缓存存储，与内存的GPU视图一致，无需手动同步。

2、如果芯片组支持CPU与GPU之间的硬件一致性协议，则该GPU支持此标记组合。

3、由于硬件的一致性，它避免了手动同步操作的开销。当可用时，缓存的、一致的内存优先于缓存的、不一致的内存类型。

4、必须用于CPU上的应用软件映射和读取的资源。

5、硬件一致性的功耗很小，所以不能用于CPU上只写的资源。对于只写资源，通过使用Not Cached，一致内存类型绕过CPU缓存。

关于LAZILY_ALLOCATED内存类型说明：

1、是一种特殊的内存类型，最初只支持GPU虚拟地址空间，而不是物理内存页面。如果访问内存，则根据需要分配物理页。

2、必须与使用VK_IMAGE_USAGE_TRANSIENT_ATTACHMENT_BIT创建的瞬态attachment一起使用。瞬态Image的目的是用作帧缓冲attachment，只存在于一个单一的渲染过程中，可以避免使用物理内存。

3、不能将数据写回全局内存。

以下是Vulkan内存标记的使用建议：

1、对于不可变资源，使用HOST_VISIBLE | HOST_COHERENT内存。

2、对于CPU上只写的资源，使用HOST_VISIBLE | HOST_COHERENT内存。

3、使用memcpy()将更新写入HOST_VISIBLE | HOST_COHERENT内存，或者按顺序写入以获得CPU write-combine单元的最佳效率。

4、使用HOST_VISIBLE | HOST_COHERENT | HOST_CACHED内存用于将资源读回CPU，如果此组合不可以，则使用HOST_VISIBLE | HOST_CACHED。

5、使用LAZILY_ALLOCATED内存用于仅在单个渲染过程中存在的临时帧缓冲区附件。

6、只将LAZILY_ALLOCATED内存用于TRANSIENT_ATTACHMENT帧缓冲区附件。

7、映射和取消映射缓冲区消耗CPU性能。因此要持久地映射经常被访问的缓冲区，例如：统一缓冲区、数据缓冲区或动态顶点数据缓冲区。

- **尽量使用零拷贝（Zero-Copy）路径。**

如下图所示，通过使用EglImage实现Camera和OpenCL共享Original Image Data，OpenCL和OpenGL ES共享Final Image Data，从而达到零拷贝：

![img](https://img2020.cnblogs.com/blog/1617944/202111/1617944-20211118220116685-2105004479.svg)

- **将内存访问分组。**

编译器使用几种启发式方法，可以识别内核中的内存访问模式，这些模式可以组合成读或写操作的突发传输。为了让编译器更好实现这种优化，内存访问应该尽可能紧密地组合在一起。

例如，将读放在内核的开头，写放在内核的结尾，可以获得最佳的效率。对更大的数据类型(如向量)的访问也会尽可能地编译为单个传输，加载1个float4比加载4个单独的float值更好。

- **合理使用Shared/Local内存。**

可以在Shader初期（如初始化），将常访问的数据先读取到Shared/Local内存，提升访问速度。

- **以行优先（Row-Major）的顺序访问内存。**

GPU通常会预读取行相邻的数据到GPU缓存中，如果着色器算法以行优先的方式访问，可以提升Cache命中率，降低带宽。

- **GPU特定带宽优化。**

Mali的Transaction elimination只有在以下情形适用：

1、采样数据为1。

2、mimap级别为1。

3、image使用了COLOR_ATTACHMENT_BIT。

4、image没有使用TRANSIENT_ATTACHMENT_BIT。

5、使用单一颜色附件。（Mali-G51 GPU及之后没有此限制）

6、有效的tile尺寸是16x16像素，像素数据存储决定了有效的tile尺寸。

Mali GPU还支持AFBC纹理，可以减少显存和带宽。

## **12.6.4后处理优化**

后处理效果会占用更大的带宽，所以非必须，尽量关闭所有后处理效果。

如果确实需要后处理，常见的优化手段如下：

1、将多个后处理效果合并成一个Shader完成。

2、降分辨率计算后处理效果。

3、尽量将后处理的数据访问保持在Tile内。

4、尽量不访问周边像素数据。如果需要，尽量保持局部性和时效性，提升缓存命中率。

5、专用的算法优化。如将高斯模糊拆分成横向模糊+竖向模糊（分离卷积核）。Filament对针对移动端的色调映射做了优化：

```glsl
// 原始的ACES色调映射。
vec3 Tonemap_ACES(const vec3 x)
{
    // Narkowicz 2015, "ACES Filmic Tone Mapping Curve”
    const float a = 2.51;
    const float b = 0.03;
    const float c = 2.43;
    const float d = 0.59;
    const float e = 0.14;
    return (x * (a * x + b)) / (x * (c * x + d) + e);
}

// 移动端版本的色调映射
vec3 Tonemap_Mobile(const vec3 x) 
{
    // Transfer function baked in,
    // don’t use with sRGB OETF!
    return x / (x + 0.155) * 1.019;
}
```

而简化后的色调映射曲线非常接近：

![img](https://img2020.cnblogs.com/blog/1617944/202111/1617944-20211118220559808-1737311187.png)

Arm对常用的后处理效果在不同的质量等级下给出了技术参考：

![img](https://img2020.cnblogs.com/blog/1617944/202111/1617944-20211118220611782-1585570517.png)





---



## 案例

GPU[渲染优化](https://zhida.zhihu.com/search?q=渲染优化&zhida_source=entity&is_preview=1)从本质上讲实际上是在优化以下两点：

**1.尽量减少渲染的指令数**

**2.尽量降低带宽的使用**

**其中在移动设备上带宽的优化尤为重要，其不仅仅影响性能，还和发热，耗电息息相关。**

如何优化带宽本质上就是合理的使用渲染资源，比如合理的使用贴图的压缩格式，合理的使用贴图的mipmap层级，合理的使用RenderTarget等等。

很多时候在ue4上做优化只需要修改对应的配置文件，但是为了追求性能的极致，有时候我们不得不修改ue4原生的[渲染管线](https://zhida.zhihu.com/search?q=渲染管线&zhida_source=entity&is_preview=1)。

**优化1 RenderTarget优化**

先明确一下，我们项目使用的是前向渲染，因此没有G-Buffer。

在优化RenderTarget的时候，我们遇到了一个问题。因为scene color rt不需要a通道，为了节省带宽同时又保证color的精度，我们希望所有平台的scene color rt都使用R11G11B10格式(在一些低端的android设备上不支持这个格式，我们回退到了R8G8B8A8)。这本来不是什么问题，但是因为后续的渲染阶段需要使用scene depth信息，比如depth fade节点。在android设备上，ue4会使用framebuffer_fetch_depth_stencil扩展来读取depth信息，但是IOS不支持这个扩展，IOS只能读取framebuffer中的scene color rt，因此它将深度值存储到了scene color rt的a通道。为了保证深度值的精度，通常我们会使用rgba16的[半浮点数](https://zhida.zhihu.com/search?q=半浮点数&zhida_source=entity&is_preview=1)格式。这样scene color rt每一个像素就变成了64位，比之前的32位足足多了一倍。如果想要扩大[深度信息](https://zhida.zhihu.com/search?q=深度信息&zhida_source=entity&is_preview=1)的精度，比如希望使用R32，那么就变成了128位，比原来多了96位带宽。为了解决这个问题，我们对ios端的渲染管线做了优化，基本思路就是：

1. scene color rt改为mrt，color1为R11G11B10格式输出颜色信息，color2为R16格式输出深度信息。
2. color2资源使用memoryless，即存储在on-chip缓存中，减少load和store操作。

这样对于16位精度的深度每个像素能节省16位带宽，32位深度能节省96位带宽，接下来我们看看如何修改ue4的渲染管线。

首先我们需要创建scene depth的rt资源，ue4使用对象池的概念来管理rt资源，我们只需要使用FindFreeElement接口就可以创建新的rt资源。

```cpp
void FSceneRenderTargets::AllocMRTSceneDepth(FRHICommandList& RHICmdList)
{
	EPixelFormat SceneDepthBufferFormat = EPixelFormat::PF_R16F;

	// Mobile non-mobileHDR is the only platform rendering to a true sRGB buffer natively
	bool MobileHWsRGB = IsMobileColorsRGB() && IsMobilePlatform(GShaderPlatformForFeatureLevel[CurrentFeatureLevel]);

	// Create the mrt scene depth.
	{
		FPooledRenderTargetDesc Desc(FPooledRenderTargetDesc::Create2DDesc(BufferSize, SceneDepthBufferFormat, DefaultColorClear, TexCreate_None, TexCreate_RenderTargetable | TexCreate_ShaderResource, false));
		Desc.Flags |= GFastVRamConfig.SceneColor;
		Desc.NumSamples = CurrentMSAACount;
		Desc.ArraySize = bRequireMultiView ? 2 : 1;
		Desc.bIsArray = bRequireMultiView;
		Desc.Flags |= MobileHWsRGB ? TexCreate_SRGB : TexCreate_None;

		if (!bKeepDepthContent)
		{
                    //使用Memoryless 
		    Desc.TargetableFlags |= TexCreate_Memoryless;
		}

		// By default do not transition to writeable because of possible multiple target states
		GRenderTargetPool.FindFreeElement(RHICmdList, Desc, MRTSceneDepth, TEXT("MRTSceneDepth"));
	}

	check(GetSceneColorForCurrentShadingPath());
}
```

接下来我们需要将rt资源attach到render pass上，相关代码如下：

```cpp
FRHITexture* ColorRTs[2] = { SceneColor, MRTSceneDepth };

FRHIRenderPassInfo MRTSceneColorRenderPassInfo
(
    2,
    ColorRTs,
    ColorTargetAction,
    SceneDepth,
    DepthTargetAction,
    FExclusiveDepthStencil::DepthWrite_StencilWrite
);

if (!bIsFullPrepassEnabled)
{
    MRTSceneColorRenderPassInfo.NumOcclusionQueries = ComputeNumOcclusionQueriesToBatch();
    MRTSceneColorRenderPassInfo.bOcclusionQueries = MRTSceneColorRenderPassInfo.NumOcclusionQueries != 0;
}
//if the scenecolor isn't multiview but the app is, need to render as a single-view multiview due to shaders
MRTSceneColorRenderPassInfo.MultiViewCount = View.bIsMobileMultiViewEnabled ? 2 : (bIsMultiViewApplication ? 1 : 0);

RHICmdList.BeginRenderPass(MRTSceneColorRenderPassInfo, TEXT("MRTSceneColorRendering"));
```

接下来我们要修改shader，首先是输出深度信息：

```cpp
void Main( 
	FVertexFactoryInterpolantsVSToPS Interpolants
	, FMobileBasePassInterpolantsVSToPS BasePassInterpolants
	, in float4 SvPosition : SV_Position
	OPTIONAL_IsFrontFace
	, out half4 OutColor	: SV_Target0
#if IOS_MRT_DEPTH && !DEFERRED_SHADING_PATH
	, out half4 OutDepth    : SV_Target1
#endif
	)
｛
    #if IOS_MRT_DEPTH
	OutDepth.r = SvPosition.z;
    #endif
 ｝
```

然后是修改读取深度信息相关的shader代码：

```text
#if IOS && PIXELSHADER 
	// The load operation here will be patched by the MetalShaderCompiler,
	// do NOT change any character in the "SubpassFetch*" macro definition, including white spaces!
	
	// 4 components: RGBA_0
	Texture2D<float4> gl_LastFragDataRGBA_0;
	#define SubpassFetchRGBA_0() gl_LastFragDataRGBA_0.Load(uint3(0, 0, 0), 0)
	// 1 component: R_1
	Texture2D<float> gl_LastFragDataR_1;
	#define SubpassFetchR_1() gl_LastFragDataR_1.Load(uint3(0, 0, 0), 0)
	// 1 component: R_4
	Texture2D<float> gl_LastFragDataR_4;
	#define SubpassFetchR_4() gl_LastFragDataR_4.Load(uint3(0, 0, 0), 0)
	//
	// Rest of SubpassFetch can be found in MetalSubpassSupport.ush
	//
	#if MOBILE_DEFERRED_SHADING
		#define DepthbufferFetchES2() SubpassFetchR_4()
	#else
		#define DepthbufferFetchES2() SubpassFetchR_1()
	#endif
#else
```

ok，大功告成，接下来我们使用xcode截帧，看看渲染管线的执行情况。

![img](https://pic1.zhimg.com/80/v2-c56dacd42a2789603adc3b0fd840fd7a_720w.webp)

可以看到 attachments中多了一个Color1用来存储深度，Color0格式使用了RG11B10Float，而且depth fade效果也正常，说明可以正确读取深度信息，最后再对比一下性能。

先看看整体性能提升，如下图：

![img](https://pic4.zhimg.com/80/v2-813376204c352572127920796341f0bf_720w.webp)

优化后提升了0.04ms，因为测试场景比较简单，所以性能优化很小，可能还不够弥补误差。接下来看看带宽的使用情况。

![img](https://pic1.zhimg.com/80/v2-c61bb8d4f5460e7cb916d61aa7052cc2_720w.webp)

写带宽明显下降，这个符合预期。因为每个像素我们节省了16位的带宽。

![img](https://pic1.zhimg.com/80/v2-1963dae7e5da3720b52ae876193991c2_720w.webp)

因为使用了MRT多渲染了一张[深度贴图](https://zhida.zhihu.com/search?q=深度贴图&zhida_source=entity&is_preview=1)，MobileBasePass多消耗了0.07ms，半透明渲染的效率提高了，是因为深度rt使用了memoryless。从上面的测试结果来看，节省带宽的目的是达到了，性能有略微提升。

**优化2 Alpha-Test Pre-Z**

还是先从概念说起，[overdraw](https://zhida.zhihu.com/search?q=overdraw&zhida_source=entity&is_preview=1)是性能的最大杀手，通俗的说overdraw就是屏幕上渲染了不应该渲染的物体，为了对抗overdraw我们使用了许多手段，比如相机裁剪&剔除，遮挡剔除，渲染排序等等，这些算法是物体级别的优化。还有像素级别的剔除，比如[early-z](https://zhida.zhihu.com/search?q=early-z&zhida_source=entity&is_preview=1)和pre-z，这两个算法是为了减少ps阶段的overdraw，对重度渲染的游戏来说是非常必要的。

early-z是在ps之前，先做深度测试，通过测试的像素才会执行ps，这个是由硬件来实现的，但是打开early-z需要一些限制条件，总结起来就是要保证early-z和late-z值相同，如果一个像素通过了early-z测试，但是在ps阶段修改了深度值或者丢弃了这个像素，深度值没有写入late-z，这个时候就会造成early-z和late-z不一致，这样可能会造成后续render pass的artifact。如果你强行打开early-z也没有问题，如果能容忍错误效果的话，而且还要看具体硬件的支持。早期的显卡early-z的深度贴图不支持边读边写，所以会先渲染一遍场景，生成pre-z贴图。然后使用这个pre-z贴图做early-z，现在大部分硬件应该不需要了吧。

Alpha-Test Pre-Z，对于开启 Alpha-Test的物体，比如树和草，它们是无法开启early-z来进行性能优化的，而恰恰树和草是非常耗性能的部分，因为数量巨大。一种方法是使用Alpha-blend来替代Alpha-Test，这样做可以开启early-z，但是这种做法需要无序半透明的支持，更浪费性能。

另外一种做法，就是先渲染一遍 Alpha-Test的物体，将深度值写入到深度/[模板缓存](https://zhida.zhihu.com/search?q=模板缓存&zhida_source=entity&is_preview=1)中，然后再渲染一遍物体，渲染的时候关闭Alpha-Test，深度测试改为相等，这样就可以开启Alpha-Test物体的early-z，从而优化性能。这部分的优化ue4已经为我们做好了，只需要打开开关即可。

```cpp
/** Affects MobileBasePassPixelShader.usf so must relaunch editor to recompile shaders. */
static TAutoConsoleVariable<int32> CVarMobileEarlyZPassOnlyMaterialMasking(
	TEXT("r.Mobile.EarlyZPassOnlyMaterialMasking"),
        //默认值改为1，强制打开
	1,
	TEXT("Whether to compute materials' mask opacity only in early Z pass for Mobile platform. Changing this setting requires restarting the editor.\n")
	TEXT("<=0: off\n")
	TEXT("  1: on\n"),
	ECVF_RenderThreadSafe | ECVF_ReadOnly
);
```

接下来看一下性能对比，如下图：

![img](https://pic1.zhimg.com/80/v2-8cea849a280c42d23e55c5fd998b551e_720w.webp)

可以看到优化效果非常明显，直接优化了14.42ms，性能提升了30%。

![img](https://pic4.zhimg.com/80/v2-897e77ed81f8a956c6f6a55ad151e681_720w.webp)

overdraw降低了24.5%。